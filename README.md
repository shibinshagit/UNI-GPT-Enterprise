# Uni-GPT Voice Assistant

ğŸ™ï¸ Professional voice-powered AI assistant for UniQube bathroom pods and kitchens. Built with Next.js, OpenAI GPT-4o-mini, and Web Speech API.

![Uni-GPT](https://img.shields.io/badge/Next.js-15-black?logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-4-38bdf8?logo=tailwindcss)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-412991?logo=openai)

## âœ¨ Features

- **ğŸ¤ Voice-First Interface** - Hands-free interaction using Web Speech API
- **ğŸ”’ Secure Backend** - API keys stored server-side, never exposed to client
- **ğŸ§  GPT-4o-mini Powered** - Advanced conversational AI with context awareness
- **ğŸ’¬ Conversation History** - Maintains context across multiple exchanges
- **ğŸ¨ Beautiful UI** - Animated voice visualization with Tailwind CSS
- **ğŸ”„ Continuous Mode** - Optional auto-listen for seamless dialogue
- **ğŸ“± Responsive Design** - Works on desktop and mobile
- **âš¡ Fast & Optimized** - Next.js 15 with Edge Runtime

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ installed
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/shibinshagit/UNI-GPT.git
   cd UNI-GPT
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Configure environment variables:**
   ```bash
   cp .env.example .env.local
   ```

   Edit `.env.local` and add your OpenAI API key:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   OPENAI_MODEL=gpt-4o-mini
   ```

4. **Run the development server:**
   ```bash
   npm run dev
   ```

5. **Open your browser:**
   Visit `http://localhost:3000`

## ğŸŒ Deploy to Vercel

### One-Click Deploy

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/shibinshagit/UNI-GPT&env=OPENAI_API_KEY,OPENAI_MODEL)

### Manual Deployment

1. **Push to GitHub** (if not already done)

2. **Import to Vercel:**
   - Go to [vercel.com](https://vercel.com)
   - Click "Add New Project"
   - Import your GitHub repository
   - Add environment variables:
     - `OPENAI_API_KEY`: Your OpenAI API key
     - `OPENAI_MODEL`: `gpt-4o-mini`
   - Click "Deploy"

3. **Your app will be live at:** `https://your-project.vercel.app`

## ğŸ¯ Usage

1. **Click the microphone button** or the animated orb
2. **Speak your request** when you see "Listening..."
   - "What's the weather today?"
   - "What's on my schedule?"
   - "Add eggs to my grocery list"
   - "What can I cook with chicken?"
3. **Listen to the response** - The assistant speaks back automatically
4. **Optional:** Enable "Continuous Conversation Mode" for hands-free dialogue

## ğŸ“ Project Structure

```
UNI-GPT/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts      # OpenAI API endpoint (server-side)
â”‚   â”œâ”€â”€ globals.css           # Global styles & animations
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â””â”€â”€ page.tsx              # Main voice assistant UI
â”œâ”€â”€ public/                   # Static assets
â”œâ”€â”€ .env.local                # Environment variables (not committed)
â”œâ”€â”€ .env.example              # Environment template
â”œâ”€â”€ next.config.ts            # Next.js configuration
â”œâ”€â”€ tailwind.config.ts        # Tailwind CSS configuration
â”œâ”€â”€ tsconfig.json             # TypeScript configuration
â””â”€â”€ package.json              # Dependencies & scripts
```

## ğŸ”§ Technical Details

### Architecture

- **Frontend:** Next.js 15 (App Router) with TypeScript
- **Styling:** Tailwind CSS 4 with custom animations
- **Voice Input:** Web Speech API (browser-native)
- **Voice Output:** Speech Synthesis API (browser-native)
- **AI Backend:** OpenAI GPT-4o-mini via Next.js API Route
- **Runtime:** Edge Runtime for low latency

### API Route

The `/api/chat` endpoint:
- Runs on Vercel Edge Runtime (ultra-fast, globally distributed)
- Accepts `messages` array and `temperature` parameter
- Returns AI-generated responses
- API key secured server-side, never exposed to client

### Browser Compatibility

| Browser | Speech Recognition | Text-to-Speech | Status |
|---------|-------------------|----------------|--------|
| Chrome | âœ… Full Support | âœ… Full Support | âœ… **Recommended** |
| Edge | âœ… Full Support | âœ… Full Support | âœ… **Recommended** |
| Safari | âš ï¸ Limited | âœ… Works | âš ï¸ Partial |
| Firefox | âŒ Not Supported | âœ… Works | âŒ Not Recommended |

**Note:** Chrome or Edge required for voice input!

## ğŸ”’ Privacy & Security

- **API keys server-side only** - Never exposed to client/browser
- **No conversation logging** - Conversations not stored on servers
- **HTTPS required** - Microphone access requires secure connection (Vercel provides this automatically)
- **Environment variables** - Sensitive data in `.env.local` (gitignored)

## ğŸ› ï¸ Development

### Available Scripts

```bash
npm run dev      # Start development server (localhost:3000)
npm run build    # Build for production
npm run start    # Start production server
npm run lint     # Run ESLint
```

### Environment Variables

Create a `.env.local` file with:

```env
OPENAI_API_KEY=sk-...          # Your OpenAI API key (required)
OPENAI_MODEL=gpt-4o-mini        # Model to use (optional, defaults to gpt-4o-mini)
```

## ğŸ—ºï¸ Roadmap

This MVP will evolve into the full Uni-GPT system:

### Phase 2 - Skills Integration
- âœ… Google Calendar integration
- âœ… Gmail integration
- âœ… Weather API (OpenWeather)
- âœ… News briefings (RSS feeds)
- âœ… Recipe suggestions & cooking timers
- âœ… Grocery list management
- âœ… Smart home controls (Matter/MQTT)

### Phase 3 - Hardware Deployment
- Wake word detection ("Uni")
- Offline ASR with Whisper
- Low-latency TTS with Piper
- Debian-based device firmware
- 80-85dB noise resistance
- Hardware mute switch

## ğŸ› Troubleshooting

### "Speech recognition not supported"
- Use Chrome or Edge browser
- Ensure you're on HTTPS (required for microphone access)
- Grant microphone permissions when prompted

### API Errors
- Verify `OPENAI_API_KEY` in `.env.local`
- Check you have OpenAI credits
- Ensure you're online
- Check Vercel function logs if deployed

### Voice Not Working
- Check browser compatibility
- Ensure speakers/audio are on
- Try different voice in browser settings

## ğŸ“„ License

Proprietary - UniQube Technologies

## ğŸ¤ Contributing

This is a client project. For questions or contributions, contact the UniQube team.

---

**Built for UniQube** | Powered by OpenAI GPT-4o-mini | Created with [Claude Code](https://claude.com/claude-code)
